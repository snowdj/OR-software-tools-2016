{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constrained least squares\n",
    "\n",
    "Let's start off by considering the classical least-squares regression problem.\n",
    "\n",
    "\\begin{align}\n",
    "\\min_x \\quad&||Ax-b||_2\\\\\n",
    "\\end{align}\n",
    "\n",
    "In this notebook, we'll see how to formulate the least squares problem using the [Convex.jl](https://github.com/JuliaOpt/Convex.jl) package and then add constraints on top of it. In constrast to previous classes, our focus will be on developing these methods from the primitives of convex optimization instead of using an off-the-shelf package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Distributions # for sampling from normal distribution\n",
    "using Convex        # for solving least-squares problem\n",
    "using ECOS          # open-source convex solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fix random seed\n",
    "srand(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first fix $A$ and $x$ and then generate $b = Ax + \\epsilon$ where $\\epsilon$ is Gaussian random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rand() generates coefficients uniformly between 0 and 1\n",
    "A = rand(1000,50); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = rand(50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = A*x + rand(Normal(0,100),1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we invoke the Convex.jl syntax to declare a set of optimization varibles $\\hat x$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x̂ = Variable(50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and declare a problem of minimizing $||Ax-b||_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "problem = minimize(norm(A*x̂-b,2)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then solve it using ECOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solve!(problem,ECOSSolver(verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And ask for the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50x1 Array{Float64,2}:\n",
       "  -0.711662\n",
       "  12.3106  \n",
       "  -8.18699 \n",
       " -16.5759  \n",
       "  13.612   \n",
       "   9.79773 \n",
       " -14.737   \n",
       "   3.98307 \n",
       "   0.15439 \n",
       "   6.40962 \n",
       "  -1.45227 \n",
       "  -3.26792 \n",
       " -22.939   \n",
       "   ⋮       \n",
       "  -2.08691 \n",
       "  -1.08507 \n",
       "  19.656   \n",
       "   0.745009\n",
       "   1.84697 \n",
       "  -6.47361 \n",
       "   3.48504 \n",
       "  39.3582  \n",
       " -21.1685  \n",
       " -16.3304  \n",
       "   0.126439\n",
       "  -7.60035 "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(x̂)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn this into a standalone function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leastsquares (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    leastsquares(A,b)\n",
    "\n",
    "Given A,b, returns the x which minimizes ||A*x-b||₂\n",
    "\"\"\"\n",
    "function leastsquares(A,b)\n",
    "    numrow,numcol = size(A)\n",
    "    x̂ = Variable(numcol)\n",
    "    problem = minimize(norm(A*x̂-b,2))\n",
    "    solve!(problem,ECOSSolver(verbose=0))\n",
    "    return evaluate(x̂)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation above the function now appears when you search for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: "
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "leastsquares(A,b)\n",
       "\\end{verbatim}\n",
       "Given A,b, returns the x which minimizes ||A*x-b||₂\n"
      ],
      "text/markdown": [
       "```\n",
       "leastsquares(A,b)\n",
       "```\n",
       "\n",
       "Given A,b, returns the x which minimizes ||A*x-b||₂\n"
      ],
      "text/plain": [
       "```\n",
       "leastsquares(A,b)\n",
       "```\n",
       "\n",
       "Given A,b, returns the x which minimizes ||A*x-b||₂\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?leastsquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leastsquares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ls = leastsquares(A,b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated coefficients from the interval $[0,1)$. How many of the coefficients are below zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x_ls .<= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [nonnegative least squares](https://en.wikipedia.org/wiki/Non-negative_least_squares) problem is\n",
    "\\begin{align}\n",
    "\\min_{x\\ge 0} \\quad&||Ax-b||_2\\\\\n",
    "\\end{align}\n",
    "\n",
    "Will the knowledge of the fact that the coefficients are nonnegative give us a better solution? Let's check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nonnegativeleastsquares (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    nonnegativeleastsquares(A,b)\n",
    "\n",
    "Given A,b, returns the x which minimizes ||A*x-b||₂ subject to x ≥ 0\n",
    "\"\"\"\n",
    "function nonnegativeleastsquares(A,b)\n",
    "    numrow,numcol = size(A)\n",
    "    x̂ = Variable(numcol)\n",
    "    problem = minimize(norm(A*x̂-b,2),\n",
    "                       x̂ >= 0) # All we changed was this!!\n",
    "    solve!(problem,ECOSSolver(verbose=0))\n",
    "    return evaluate(x̂)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_nnls = nonnegativeleastsquares(A,b);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x_nnls .< 0) # all components are nonnegative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we compare the two solutions? An easy way is the distance from the true solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.86991822320907"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(x-x_ls,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.88255684742728"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(x-x_nnls,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way to compare the two solutions is to check their predictive power. How well do they predict $b$ if we resample the noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out of sample test\n",
    "b2 = A*x + rand(Normal(0,10),1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832.7949480457804"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(A*x_ls-b2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359.01072183471734"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(A*x_nnls-b2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check**: what would happen if we just used $\\hat x = 0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524.7639978985346"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(b2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we just guessed ``b`` from the original observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3256.2477400241655"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(b-b2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**\\[Exercise\\]**: Interval-constrained least squares.\n",
    "\n",
    "> Recall we generated the coefficients of x from $[0,1)$. Does it help the performance of the regression if we constrain $0 \\le \\hat x \\le 1$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.3",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
