{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed-integer programming: Tools and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations research often involves models where you need discrete decisions. \n",
    "\n",
    "Oftentimes, this will lead to problems that are $NP$-hard. What do you do?\n",
    "\n",
    "1. Give up\n",
    "2. Settle for approximate solutions\n",
    "2. Try the simplest thing imaginable: **enumeration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the simple knapsack. Iain wants to carry items to the pawn shop to get some extra cash. He has $N$ items, each with a weight $w_i$ and a price $p_i$. Iain hasn't been to the gym lately, so he can only carry $C$ kilos. How does he choose what to bring with him?\n",
    "\n",
    "We can model this as an integer optimization problem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\max& \\sum_{i=1}^N p_i x_i \\\\\n",
    "\\text{s.t.}& \\sum_{i=1}^N w_i x_i \\leq C \\\\\n",
    "& x_i \\in \\{0,1\\} \\quad \\forall i = 1,\\ldots,N\n",
    "\\end{align*}\n",
    "\n",
    "How would you solve this? The simple way is just to consider each possible value for $x$ and compare the cost. After Iain has weighed all $2^N$ possible collections of items (and verified that he can lift them at once), he just chooses the best set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this approach to enumeration like this:\n",
    "![Enumerate](http://www.mit.edu/~huchette/.tmp/enumerate.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But again, we don't want to _actually_ enumerate every solution. Bear with me while I construct a binary tree like so:\n",
    "![Full Tree](http://www.mit.edu/~huchette/.tmp/fulltree.svg)\n",
    "It's rooted at what we call the _relaxation_: none of variables have integrality enforced. As we go down leaves of the tree, we add pick a variable to _branch_ on, and create two descended nodes that fix that variable to one of its possible values. If we follow the tree all the way to the bottom, we reach our enumeration from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is even more complexity, and what does it buy us? Well, with the tree structure in place, we can make a simple observation about bounding. Since as we go down the arcs of the tree we restrict our problem more and more, we must have that:\n",
    "\n",
    ">If node ``q`` is descended from node ``p``, we must have that the optimal cost of subproblem ``q`` is no more than that for node ``p``\n",
    "\n",
    "This leads us to a powerful tool in solving these enumeration problems: \n",
    "\n",
    ">If I can show you that the optimal cost for subproblem ``q`` is _less_ than the optimal cost for the original problem, the same is true for any descendent of ``q``. \n",
    "\n",
    "That is, we can _prune_ the tree and safely discard some nodes, kind of like this:\n",
    "![Pruning](http://www.mit.edu/~huchette/.tmp/fathom.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Consider the following (small) knapsack problem:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\max\\quad& x + y \\\\\n",
    "    \\text{s.t.}\\quad& x + 2y \\leq 1.5 \\\\\n",
    "    & 0 \\leq x, y \\leq 1 \\\\\n",
    "    & x, y \\in \\{0,1\\}\n",
    "\\end{align*}\n",
    "\n",
    "What does the relaxation (no integrality restrictions) of this problem look like?\n",
    "\n",
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig1.svg)\n",
    "\n",
    "First, we solve the LP relaxation and get $(x^*,y^*) = (1,0.25)$. \n",
    "\n",
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig2.svg)\n",
    "\n",
    "This isn't integer feasible, so we branch on $y$. The subproblem with $y = 1$ is infeasible, and the subproblem with $y = 0$ is feasible with solution $(x^*,y^*) = (1,0)$. This is integer feasible, so we update our lower bound. We've also exhausted the tree, so we have our optimal solution!\n",
    "\n",
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig3.svg)\n",
    "\n",
    "In the worst case scenario, the branch-and-bound scheme can end up solving even _more_ subproblems than if we just enumerated everything to begin with. For the scheme to work well, we need to prune large portions of the tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branch-and-bound\n",
    "We'll keep track of a global _lower bound_ $LB$ for our problem. Each node ``q`` will have an upper bound $UB_q$ that it inherents from its parent. If we get to the point where we have solved all subproblems (or, ideally, pruned off a great deal of them), we know that we're optimal. To do this we'll also keep track of a list $L$ of subproblems left to solve; initially, it's just the relaxation. The procedure is:\n",
    "\n",
    "While $L$ is not empty, pick a subproblem ``q`` out of our list $L$ and solve it. \n",
    "1. ``if`` ``q`` is infeasible, ``continue``\n",
    "2. ``if`` the solution is integer feasible, update the lower bound $LB$ if the cost is higher than what we had before\n",
    "3. ``if``  the relaxation value is less than our global $LB$ ``continue``\n",
    "4. ``else`` pick a non-integer variable $i$ and _branch_ by adding two subproblems to $L$: \n",
    "    * One with $x_i = 0$\n",
    "    * Another with $x_i = 1$\n",
    "\n",
    "Branch-and-bound is sometimes called an _implicit enumeration_ scheme because of step 3: we avoid solving any subproblems that we can prove won't produce the optimal solution.\n",
    "\n",
    "** The \"magic\" of modern MIP solvers largely comes down to pruning massive portions of the tree **\n",
    "\n",
    "## Things you maybe don't need to know about (but are cool anyway)\n",
    "\n",
    "1. Solvers _warm start_ using dual simplex: old optimal solutions are used as starting points at nodes, reducing number of simplex pivots required.\n",
    "2. Solvers usually will refine the root node for a while, adding cuts and such repeatedly. We'll see this below in solver output.\n",
    "\n",
    "## Stuff you should care about\n",
    "\n",
    "1. Cuts (improve the _upper bounds_)\n",
    "2. Heuristics (improve the _lower bounds_)\n",
    "3. Presolve (_simplify_ everything before we build the tree)\n",
    "4. Branching strategies (construct the tree in a smart way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cuts\n",
    "\n",
    "Cuts are inequalities that are _valid_ (don't cut off any feasible integer points) and _strengthen_ the formulation (chop off some of the region feasible for the relaxation)\n",
    "\n",
    "Three main types of cuts:\n",
    "\n",
    "1. General purpose (e.g. CG, split, MIR)\n",
    "2. Structure-specific (e.g. knapsack cover, clique)\n",
    "3. Problem-specific (whatever _you_ cook up)\n",
    "\n",
    "### Example \n",
    "\n",
    "Let's go back to our knapsack example and imagine that had been a bit smarter and realized that $x + \\frac{4}{3}y \\leq 1$ is feasible for all integer feasible points. If we add this to our formulation, we have the optimal solution at the root node!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig4.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Heuristics\n",
    "\n",
    "You can add integer feasible solutions into the branch-and-bound scheme to improve the lower bound. These can come from\n",
    "\n",
    "1. Problem-specific heuristics\n",
    "2. Neighborhood search\n",
    "3. Rounding or \"polishing\"\n",
    "\n",
    "### Example\n",
    "\n",
    "After we've already solved it twice, it's easy to see that the optimal solution for our knapsack is $(1,0)$. So, we can just start out the branch-and-bound procedure with $LB = 1$.\n",
    "\n",
    "More generally, if we're solving a knapsack problem, one simple heuristic is to add a _greedy solution_ where you iteratively add the best available item to the sack until you run out of room. This will often be a very good solution, and is a simple example of a problem-specific heuristic scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig5](http://www.mit.edu/~huchette/.tmp/fig5.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Presolve\n",
    "\n",
    "Modern MIP solvers have a litany of techniques to simplify problems _before_ constructing the tree. \n",
    "\n",
    "* Variable/constraint bounds tightening\n",
    "* Logical inferences\n",
    "* General cleanup (remove redundant variables, constraints)\n",
    "\n",
    "By shrinking problems, presolve potentially shrinks\n",
    "\n",
    "* the B&B tree (fewer binary variables)\n",
    "* The node solve time (smaller LP relaxations)\n",
    "\n",
    "### Example\n",
    "\n",
    "For our problem\n",
    "\\begin{align*}\n",
    "    \\max\\:& x + y \\\\\n",
    "    \\text{s.t.}\\:& x + 2y \\leq 1.5 \\\\\n",
    "    & x, y \\in \\{0,1\\}\n",
    "\\end{align*}\n",
    "\n",
    "we can perform bounds tightening to get\n",
    "\n",
    "\\begin{align*}\n",
    "    \\max\\:& x + y \\\\\n",
    "    \\text{s.t.}\\:& x + 2y \\leq 1 \\\\\n",
    "    & x, y \\in \\{0,1\\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig6.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can reason that, since $x,y \\in \\{0,1\\}$, we cannot have $y=1$, and so we can reduce our problem to \n",
    "\n",
    "\\begin{align*}\n",
    "    \\max\\:& x \\\\\n",
    "    & x \\in \\{0,1\\}\n",
    "\\end{align*}\n",
    "\n",
    "Which we can then solve in closed form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Branching strategies\n",
    "\n",
    "Different paths through the B&B tree can see drastically different performance:\n",
    "\n",
    "* Missing a node that produces a good feasible solution will mean you add nodes to your list you otherwise would have pruned\n",
    "* Choosing nodes that would otherwise be pruned just slows you down\n",
    "\n",
    "How do we know _a priori_ what a good branching strategy is, though? \n",
    "\n",
    "We don't really, but you can make informed guesses. \n",
    "\n",
    "Consider another small problem:\n",
    "\\begin{align*}\n",
    "    \\max\\:& y \\\\\n",
    "    \\text{s.t.}\\:& -x + y \\leq \\frac{1}{3} \\\\\n",
    "    & x + y \\leq \\frac{4}{3} \\\\\n",
    "    & 0 \\leq x,y \\leq 1 \\\\\n",
    "    & x, y \\in \\{0,1\\}\n",
    "\\end{align*}\n",
    "If we solve the relaxation, we get an optimal solution of $(x^*,y^*) = (\\frac{1}{2},\\frac{5}{6})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig7.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a choice: both coordinates are fractional, so we can branch on either. If we branch on $y$, we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig8.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The branch with $y=0$ gives us an optimal solution in $(0,1)$, and the $y=1$ branch is infeasible, so we have no more branches to take and we are done. But if we had branched on $x$ instead,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](http://www.mit.edu/~huchette/.tmp/fig9.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal solution for both branches is still fractional, so we have to branch again. If we have, say, 1000 binary variables instead of just two, we see how branching strategies can have an enormous effect on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "MIP solvers are magical in two ways:\n",
    "\n",
    "1. They can be incredibly effective\n",
    "2. They can be incredibly opaque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding solver output\n",
    "\n",
    "Let's solve our simple knapsack problem for Iain and see what the solver spits out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using JuMP, Gurobi\n",
    "m = Model(solver=GurobiSolver())\n",
    "\n",
    "@defVar(m, x, Bin)\n",
    "@defVar(m, y, Bin)\n",
    "\n",
    "@addConstraint(m, x + 2y ≤ 1.5)\n",
    "@setObjective(m, Max, x + y)\n",
    "\n",
    "solve(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? First, Gurobi is telling us some summary statistics about our problem:\n",
    "```\n",
    "Optimize a model with 1 rows, 2 columns and 2 nonzeros\n",
    "Coefficient statistics:\n",
    "  Matrix range    [1e+00, 2e+00]\n",
    "  Objective range [1e+00, 1e+00]\n",
    "  Bounds range    [1e+00, 1e+00]\n",
    "  RHS range       [2e+00, 2e+00]\n",
    "```\n",
    "Next, we see that Gurobi ran some heuristic procedure _before_ constructing the tree, and produced a feasible solution with value 1:\n",
    "```\n",
    "Found heuristic solution: objective 1\n",
    "```\n",
    "Next, Gurobi runs presolve and removes 1 row and 2 columns: in other words, it removes everything! (It also does this really quickly).\n",
    "```\n",
    "Presolve removed 1 rows and 2 columns\n",
    "Presolve time: 0.00s\n",
    "```\n",
    "Since there isn't anything left to the problem, it doesn't have to look at any nodes, and it does this about as fast as you would expect:\n",
    "```\n",
    "Explored 0 nodes (0 simplex iterations) in 0.00 seconds\n",
    "```\n",
    "Gurobi is done solving the problem, so now it tells us some summary statistics: the objective value of the best feasible solution, the best upper bound, and the percent gap between the two:\n",
    "```\n",
    "Optimal solution found (tolerance 1.00e-04)\n",
    "Best objective 1.000000000000e+00, best bound 1.000000000000e+00, gap 0.0%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kind of dull since Gurobi solves this before we ever get to the branch-and-bound tree! Let's cook up a problem that's a little more interesting. What about more items, and more knapsacks! If $N=350$, naïve enumeration would create $2^{350}$ nodes, which would take quite some time. How does the solver actually tackle it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srand(100)\n",
    "N = 350\n",
    "\n",
    "m = Model(solver=GurobiSolver())\n",
    "@defVar(m, x[1:N], Bin)\n",
    "for _ in 1:10\n",
    "    @addConstraint(m, dot(rand(N), x) ≤ N / 50)\n",
    "end\n",
    "\n",
    "@setObjective(m, Max, dot(rand(N), x))\n",
    "\n",
    "solve(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The junk at the top is mostly the same, but now we force the solver to actually do some work. First, it finds an alright heuristic solution:\n",
    "```\n",
    "Found heuristic solution: objective 6.86518\n",
    "```\n",
    "Presolve isn't able to do much of anything (probably because the problem is dense):\n",
    "```\n",
    "Presolve time: 0.00s\n",
    "Presolved: 10 rows, 350 columns, 3500 nonzeros\n",
    "Variable types: 0 continuous, 350 integer (350 binary)\n",
    "```\n",
    "Then it solves the relaxation and reports back:\n",
    "```\n",
    "Root relaxation: objective 1.599653e+01, 33 iterations, 0.00 seconds\n",
    "```\n",
    "Now it explores the branch-and-bound tree, and updates us as it goes along:\n",
    "```\n",
    "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
    " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
    "\n",
    "     0     0   15.99653    0   10    6.86518   15.99653   133%     -    0s\n",
    "H    0     0                      15.0893488   15.99653  6.01%     -    0s\n",
    "H    0     0                      15.4881914   15.99653  3.28%     -    0s\n",
    "     0     0   15.99099    0   13   15.48819   15.99099  3.25%     -    0s\n",
    "     0     0   15.99099    0   10   15.48819   15.99099  3.25%     -    0s\n",
    "     0     0   15.99099    0   13   15.48819   15.99099  3.25%     -    0s\n",
    "     0     0   15.99084    0   13   15.48819   15.99084  3.25%     -    0s\n",
    "     0     2   15.99084    0   13   15.48819   15.99084  3.25%     -    0s\n",
    "H52632 17202                      15.4995833   15.75331  1.64%   3.9    3s\n",
    " 72254 22464   15.71500   38    9   15.49958   15.72628  1.46%   3.9    5s\n",
    "H101962 27634                      15.5156084   15.69895  1.18%   3.9    6s\n",
    " 172259 28853   15.62486   37   10   15.51561   15.64580  0.84%   3.8   10s\n",
    "```\n",
    "What does this all mean? Let's look at just the first line:\n",
    "```\n",
    "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
    " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
    "\n",
    "     0     0   15.99653    0   10    6.86518   15.99653   133%     -    0s\n",
    "```\n",
    "We see that the information is broken down into four main columns:\n",
    "\n",
    "1. ``Nodes``: Global node information\n",
    "    * how many nodes have we looked at\n",
    "    * how many do we have in our queue\n",
    "2. ``Current Node``\n",
    "    * objective\n",
    "    * depth in the tree\n",
    "    * number of noninteger variables in the solution\n",
    "3. ``Objective Bounds``\n",
    "    * Best incumbent (lower bound)\n",
    "    * node upper bound\n",
    "    * the gap between the two\n",
    "4. ``Work``\n",
    "    * average simplex iterations per node\n",
    "    * total elapsed time\n",
    "\n",
    "Finally, we get a neat summary of the cutting planes Gurobi found useful:\n",
    "```\n",
    "Cutting planes:\n",
    "  Gomory: 10\n",
    "  Cover: 5\n",
    "```\n",
    "All told, we explored 257,956  nodes, much less than the $2^{100}$ we were worried about. All this only took 951,664 simplex iterations and 13.70 seconds, which shows the power of _warm starting_ in the branch-and-bound scheme.\n",
    "\n",
    "Now what about those ``H``s that appear? That tells us that Gurobi ran a heuristic and found a new best solution. You can see for yourself, as the incumbent value increases while the bound remains the same; we also don't get any ``Current Node`` information:\n",
    "```\n",
    "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
    " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
    "\n",
    "     0     0   15.99653    0   10    6.86518   15.99653   133%     -    0s\n",
    "H    0     0                      15.0893488   15.99653  6.01%     -    0s\n",
    "```\n",
    "You'll also sometimes see a ``*`` instead of the ``H``, which says that the feasible solution came from branching instead of heuristics.\n",
    "\n",
    "Gurobi likes to spare your screen, so it doesn't dump information about every node, but will update you periodically as it works through the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver parameters: Should you bother?\n",
    "\n",
    "Gurobi (and other high-quality solvers) allow you to tweak a wide range of different parameters; _sometimes_ tuning these can drastically improve performance. It can be kind of intimidating, though: Gurobi has over 100 parameters, so which are the important ones?\n",
    "\n",
    "Some useful ones:\n",
    "\n",
    "* ``TimeLimit``: how long the solver will run before giving up\n",
    "* ``NodeLimit``: how many nodes to explore before giving up\n",
    "* ``MIPGap``: termination criterion for relative gap $\\frac{UB-LB}{LB}$\n",
    "* ``MIPFocus``: High-level controls on solver priority (proving optimality or increasing bound or finding optimal solution)\n",
    "\n",
    "Is that it? Well, no, but you probably need domain knowledge about your problem to go much further. There's an alternative: Gurobi has a parameter tuning feature you can try to \"learn\" good parameter settings for a particular model. Try it out if you aren't quite happy with your performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.0",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
